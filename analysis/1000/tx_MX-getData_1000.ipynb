{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy \n",
    "import scipy.stats as stats\n",
    "from scipy import stats\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "import copy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineCSVs(datafolder):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        datafolder = path to data \n",
    "    Returns:\n",
    "        df of all participant data \n",
    "        OR\n",
    "        df for singlle participant\n",
    "    \"\"\"\n",
    "        \n",
    "    #checks if path is a file\n",
    "    isFile = os.path.isfile(datafolder)\n",
    "\n",
    "    #checks if path is a directory\n",
    "    \n",
    "    isDirectory = os.path.isdir(datafolder)\n",
    "    \n",
    "    if isDirectory == True:\n",
    "        data = []\n",
    "        for filename in os.listdir(datafolder):\n",
    "            if 'csv' in filename:\n",
    "                path = datafolder + \"/\" + filename\n",
    "                df = pd.read_csv(path, index_col=None, header=0)\n",
    "                if df.experimentName.unique()=='final-intermixed-textured':\n",
    "                    if 'VE1000' in df.sequenceName.unique()[0]:\n",
    "                        subjID = df.subjID.unique()[0]\n",
    "                        data.append(df)\n",
    "\n",
    "        input_frame = pd.concat(data, axis=0, ignore_index=True)\n",
    "        \n",
    "    if isFile == True:\n",
    "        if 'csv' in datafolder:\n",
    "            input_frame = pd.read_csv(datafolder, index_col=None, header=0)\n",
    "    \n",
    "    print('Number of participants before cleaning: ', len(input_frame.subjID.unique()))\n",
    "\n",
    " \n",
    "    return input_frame\n",
    "\n",
    "\n",
    "def feet_to_meters(ft):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        ft = float value in feet \n",
    "        \n",
    "    returns:\n",
    "        m = float value converted to meters \n",
    "    \"\"\"\n",
    "    m = ft * 0.3048\n",
    "    return m\n",
    "\n",
    "def getUnitConveredData(datafolder):\n",
    "    '''\n",
    "    Args: \n",
    "        datafolder = path to data  \n",
    "        \n",
    "    returns:\n",
    "        df with all estimates converted to meters      \n",
    "    '''\n",
    "    input_data = combineCSVs(datafolder) # combine CSVs from all participants \n",
    "    \n",
    "    for idx, row in input_data.iterrows():\n",
    "        unit = row['unitSelection']\n",
    "        # if estimate was made in feet, convert to meters \n",
    "        if unit == 'feet':\n",
    "            estim_ft = row['depth_estimate']\n",
    "            estim_m = feet_to_meters(estim_ft)\n",
    "            # update depth estimates in existing dataframe\n",
    "            input_data.at[idx, 'depth_estimate'] = estim_m\n",
    "\n",
    "    \n",
    "    return input_data\n",
    "\n",
    "def cleanAgeResponses(datafolder):\n",
    "    '''\n",
    "    Args: \n",
    "        datafolder = path to data  \n",
    "        \n",
    "    returns:\n",
    "        df with cleaned reported age \n",
    "    '''\n",
    "    input_data = getUnitConveredData(datafolder)\n",
    "    \n",
    "    for idx, row in input_data.iterrows():\n",
    "        age = row['age']\n",
    "        # if year of birth was given, convert to age\n",
    "        today = datetime.date.today()\n",
    "        year = today.year\n",
    "        if age > 2000:\n",
    "            actual_age = year-age\n",
    "            # update age in existing dataframe\n",
    "            input_data.at[idx, 'age'] = actual_age\n",
    "            print(row['subjID'])\n",
    "            print(actual_age, age)\n",
    "\n",
    "\n",
    "    return input_data    \n",
    " \n",
    "\n",
    "def catchTrial_cleaning(path, correct_requirement, sequence_count):\n",
    "    '''\n",
    "    Participants complete 6 catch trials total to ensure that they are doing the task.\n",
    "    If less than 4/6 catch trials are correct, the participant is excluded.  \n",
    "    '''\n",
    "    \n",
    "    df = cleanAgeResponses(path)\n",
    "    \n",
    "    all_subjIDs = df.subjID.unique()\n",
    "    remove = []\n",
    "    subj_sequence = {}\n",
    "    df2_list = []\n",
    "    \n",
    "    for subj in all_subjIDs:\n",
    "#         print(subj)\n",
    "        subj_df = df.loc[df['subjID'] == subj]\n",
    "        cleaned_subj_df = subj_df.copy(deep=True) # prevent setting with copy warning\n",
    "        subj_sequence[subj] = subj_df.sequenceName.unique()[0]\n",
    "        \n",
    "        count_correct = 0\n",
    "        for idx, row in subj_df.iterrows():\n",
    "            stim = row['stimulus']\n",
    "            if stim.split('/')[0] == 'catch_stimuli':\n",
    "                ####### VERSION WHERE CATCH TRIALS ARE ATTENTION CHECK: IMAGE HAS NO TARGET\n",
    "                if row[\"depth_estimate\"] == 0:\n",
    "                    count_correct += 1\n",
    "\n",
    "                # remove catch trial \n",
    "                cleaned_subj_df.drop([idx], inplace=True)\n",
    "\n",
    "        if count_correct < correct_requirement:\n",
    "            remove.append(subj)\n",
    "            print(count_correct)\n",
    "        else:\n",
    "            sequence_count[subj_df.sequenceName.unique()[0]] += 1\n",
    "        \n",
    "        df2_list.append(cleaned_subj_df)\n",
    "    \n",
    "    df2 = pd.concat(df2_list)\n",
    "    print(\"Number of participants that did not pass the catch trial check:\", len(remove))\n",
    "    print(\"Participants that were removed:\",remove)\n",
    "            \n",
    "    for subj in remove:\n",
    "        df2.drop(df2[df2['subjID'] == subj].index, inplace = True) \n",
    "    \n",
    "    return df2\n",
    "    \n",
    "\n",
    "def removeMissedTrials(input_data, num_trials):\n",
    "    \"\"\"\n",
    "    Participants were told that if they missed a trial, to respond '0'.\n",
    "    This function removes those trials, and keeps track of:\n",
    "    (1) How many missed trials per participant\n",
    "    (2) Number of missed trials per duration \n",
    "    (3) Number of missed trials per sequence \n",
    "    \"\"\"\n",
    "#     input_data = cleanAgeResponses(datafolder)\n",
    "    \n",
    "    missedTrials_participants = {}\n",
    "    missedTrials_durations = {}\n",
    "    missedTrials_sequences = {}\n",
    "    \n",
    "    \n",
    "    for idx, row in input_data.iterrows():\n",
    "        estimate = row['depth_estimate']\n",
    "        if estimate == 0.0:\n",
    "            subjID = row['subjID']\n",
    "            duration = row['duration']\n",
    "            sequenceName = row['sequenceName']\n",
    "            \n",
    "            if subjID not in missedTrials_participants:\n",
    "                missedTrials_participants[subjID] = 1\n",
    "            else:\n",
    "                missedTrials_participants[subjID] += 1\n",
    "\n",
    "            if duration not in missedTrials_durations:\n",
    "                missedTrials_durations[duration] = 1\n",
    "            else:\n",
    "                missedTrials_durations[duration] += 1\n",
    "            \n",
    "            if sequenceName not in missedTrials_sequences:\n",
    "                missedTrials_sequences[sequenceName] = 1\n",
    "            else:\n",
    "                missedTrials_sequences[sequenceName] += 1\n",
    "            \n",
    "#             print(subjID, duration, sequenceName)\n",
    "            \n",
    "            # remove trials with depth estimate = 0 \n",
    "            input_data.drop(idx, inplace=True)\n",
    "    \n",
    "    # remove participants data if the participant's missed trial count is 10% or more of num_trials\n",
    "    threshold = math.floor(num_trials * 0.1)\n",
    "#     print(\"Missing Trial Count Threshold: \", threshold)\n",
    "    remove_ids = []\n",
    "    for key in missedTrials_participants:\n",
    "        if missedTrials_participants[key] >= threshold:\n",
    "            remove_ids.append(key)\n",
    "    print(\"Number of participants with 10% or more missed trials: \", len(remove_ids))\n",
    "            \n",
    "    for subj in remove_ids:\n",
    "        input_data.drop(input_data[input_data['subjID'] == subj].index, inplace = True) \n",
    "\n",
    "    # Note if a particular participant, duration, or sequence has maximum missing trials\n",
    "    # ** If the participant had no missed trials, then ID will not show up in dict \n",
    "#     print(\"Missed Trials\")\n",
    "#     print(missedTrials_participants)\n",
    "#     print(missedTrials_durations)\n",
    "#     print(missedTrials_sequences)\n",
    "\n",
    "    \n",
    "    return input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/prachimahableshwarkar/Documents/GW/FacialAge/FacialAge_MTurk/BNav_EC2/DepthDuration/MX_fS_VE_MTurk/data_1000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_path = '/Users/prachimahableshwarkar/Documents/GW/FacialAge/FacialAge_MTurk/BNav_EC2/DepthDuration/MX_fS_VE_MTurk/jsons'\n",
    "\n",
    "sequences_count_dict = {}\n",
    "for seq in os.listdir(sequences_path):\n",
    "    if 'VE1000' in seq:\n",
    "        sequences_count_dict['jsons/'+seq] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participants before cleaning:  434\n",
      "0\n",
      "2\n",
      "3\n",
      "Number of participants that did not pass the catch trial check: 3\n",
      "Participants that were removed: [779583, 728446, 667592]\n"
     ]
    }
   ],
   "source": [
    "catch_trial_cleaned_data = catchTrial_cleaning(path, 4, sequences_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the image name as a column in the df \n",
    "catch_trial_cleaned_data['imageName'] = catch_trial_cleaned_data.apply(lambda row: row.stimulus.split('/')[1].split('_')[0], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participants with 10% or more missed trials:  21\n"
     ]
    }
   ],
   "source": [
    "missed_trial_cleaned_data = removeMissedTrials(catch_trial_cleaned_data, num_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RT_Cleaning(df, outlier_range, num_trials):\n",
    "    #List unique values in the df['subjID'] column\n",
    "    all_subjIDs = df.subjID.unique()\n",
    "    \n",
    "    remove = []\n",
    "    df2_list = []\n",
    "    for subj in all_subjIDs:\n",
    "        count = 0\n",
    "        subj_df = df.loc[df['subjID'] == subj]\n",
    "        cleaned_subj_df = subj_df.copy(deep=True) # prevent setting with copy warning \n",
    "        # calculate subject's average trial RT \n",
    "        average_trial_RT = subj_df[\"trial_RT\"].mean()\n",
    "        std_trial_RT = subj_df[\"trial_RT\"].std()\n",
    "\n",
    "        for idx, row in subj_df.iterrows():\n",
    "            RT = row[\"trial_RT\"]\n",
    "            if RT < outlier_range[0]: # outlier\n",
    "                cleaned_subj_df.drop([idx], inplace=True)\n",
    "                count += 1\n",
    "#                 print(RT)\n",
    "            if RT > outlier_range[1]:\n",
    "                cleaned_subj_df.drop([idx], inplace=True)\n",
    "                count += 1\n",
    "#                 print(RT)\n",
    "                \n",
    "        threshold = math.floor(num_trials * 0.1)\n",
    "        if count >= threshold:\n",
    "            remove.append(subj)\n",
    "        \n",
    "        df2_list.append(cleaned_subj_df)\n",
    "    \n",
    "    df2 = pd.concat(df2_list)\n",
    "            \n",
    "    print(\"Number of Participants with 10% or more trials outside their RT range: \", len(remove))\n",
    "    \n",
    "#     for index, row in df2.iterrows():\n",
    "#         if row['subjID'] in remove:\n",
    "#             df2.drop(index, inplace=True)\n",
    "            \n",
    "    for subj in remove:\n",
    "        df2.drop(df2[df2['subjID'] == subj].index, inplace = True) \n",
    "        print(subj)\n",
    "                \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Participants with 10% or more trials outside their RT range:  46\n",
      "208835\n",
      "815873\n",
      "806885\n",
      "242290\n",
      "196862\n",
      "527411\n",
      "933118\n",
      "450327\n",
      "546987\n",
      "906353\n",
      "530371\n",
      "589274\n",
      "545695\n",
      "784848\n",
      "778635\n",
      "291051\n",
      "672462\n",
      "209842\n",
      "331115\n",
      "670523\n",
      "472642\n",
      "910910\n",
      "386642\n",
      "348842\n",
      "516929\n",
      "811476\n",
      "347207\n",
      "209320\n",
      "455535\n",
      "328794\n",
      "898096\n",
      "229024\n",
      "716907\n",
      "151804\n",
      "669687\n",
      "767364\n",
      "629621\n",
      "307932\n",
      "783637\n",
      "444494\n",
      "295403\n",
      "872205\n",
      "604916\n",
      "272069\n",
      "742321\n",
      "616166\n"
     ]
    }
   ],
   "source": [
    "RT_cleaned_data = RT_Cleaning(missed_trial_cleaned_data, [250, 10000], num_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeatResponses_Cleaning(df, min_unique_responses):\n",
    "    \"\"\"\n",
    "    Some participants gave'junk data' - same number repeated for many trials \n",
    "    Count the frequency of unique responses entered by the participant. \n",
    "    \"\"\"\n",
    "    #List unique values in the df['subjID'] column\n",
    "    all_subjIDs = df.subjID.unique()\n",
    "    \n",
    "    remove = []\n",
    "    max_repeats_distribution = []\n",
    "    num_unique_responses_distribution = []\n",
    "    for subj in all_subjIDs:\n",
    "        subj_df = df.loc[df['subjID'] == subj]\n",
    "        # ideally, the max repeats and num_unique_responses should be ~ 48 since there are 48 imgs at each depth bin \n",
    "        count_depth_estimates = subj_df['depth_estimate'].value_counts()\n",
    "        num_unique_responses = len(count_depth_estimates)\n",
    "        num_unique_responses_distribution.append(num_unique_responses)\n",
    "        max_repeats = count_depth_estimates.max()\n",
    "        max_repeats_distribution.append(max_repeats)\n",
    "        if num_unique_responses < min_unique_responses:\n",
    "#             print(num_unique_responses)\n",
    "            remove.append(subj)\n",
    "    print('Number of participants with less than 6 unique responses:', len(remove))\n",
    "    \n",
    "    avg_max_repeats = np.array(max_repeats_distribution).mean()\n",
    "    std_max_repeats = np.array(max_repeats_distribution).std()\n",
    "    \n",
    "    for subj in all_subjIDs:\n",
    "        subj_df = df.loc[df['subjID'] == subj]\n",
    "        count_depth_estimates = subj_df['depth_estimate'].value_counts()\n",
    "        max_repeats = count_depth_estimates.max()\n",
    "\n",
    "        outlierrange = [avg_max_repeats - (3*std_max_repeats), avg_max_repeats + (3*std_max_repeats)]\n",
    "        if max_repeats < outlierrange[0]:\n",
    "            if subj not in remove:\n",
    "                remove.append(subj)\n",
    "                print(True)\n",
    "        if max_repeats > outlierrange[1]:\n",
    "            if subj not in remove:\n",
    "                remove.append(subj)\n",
    "\n",
    "    print(\"Number of total participants removed: repeat responses: \", len(remove))\n",
    "    \n",
    "#     for index, row in df.iterrows():\n",
    "#         if row['subjID'] in remove:\n",
    "#             df.drop(index, inplace=True)\n",
    "            \n",
    "    for subj in remove:\n",
    "        df.drop(df[df['subjID'] == subj].index, inplace = True) \n",
    "\n",
    "    \n",
    "    return df, max_repeats_distribution, num_unique_responses_distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participants with less than 6 unique responses: 29\n",
      "Number of total participants removed: repeat responses:  29\n"
     ]
    }
   ],
   "source": [
    "repeat_resp_cleaned_data, max_repeats_distrib, num_unique_distrib = repeatResponses_Cleaning(RT_cleaned_data, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalTrialCountCheck(df, num_trials):\n",
    "    \"\"\"\n",
    "    If more then 10% of a participants data is missing, remove the participant\n",
    "    \"\"\"\n",
    "    #List unique values in the df['subjID'] column\n",
    "    all_subjIDs = df.subjID.unique()\n",
    "    \n",
    "    remove = []\n",
    "    for subj in all_subjIDs:\n",
    "        subj_df = df.loc[df['subjID'] == subj]\n",
    "        count_trials = len(subj_df.index)\n",
    "        threshold_trials_remaining = num_trials - math.floor(num_trials * 0.1)\n",
    "\n",
    "        if count_trials <= threshold_trials_remaining:\n",
    "            remove.append(subj)\n",
    "            \n",
    "    print(\"Number of Participants with >= 10% trials removed: \", len(remove))\n",
    "\n",
    "            \n",
    "    for subj in remove:\n",
    "        df.drop(df[df['subjID'] == subj].index, inplace = True) \n",
    "                    \n",
    "    print(\"Number of participants left: \",len(df.subjID.unique()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Participants with >= 10% trials removed:  11\n",
      "Number of participants left:  324\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = finalTrialCountCheck(repeat_resp_cleaned_data, num_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = cleaned_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_data.sequenceName.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stds = []\n",
    "for subj in final_data.subjID.unique():\n",
    "    subj_df = final_data.loc[final_data['subjID']==subj]\n",
    "    avg_response = subj_df['depth_estimate'].mean()\n",
    "    std_response = subj_df['depth_estimate'].std()\n",
    "    all_stds.append(std_response)\n",
    "    # if avg_response > 30:\n",
    "    #     print(avg_response, subj)\n",
    "\n",
    "avg_stds = np.mean(np.array(all_stds))\n",
    "std_stds = np.std(np.array(all_stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713930\n",
      "894847\n",
      "830607\n"
     ]
    }
   ],
   "source": [
    "values_to_drop = []\n",
    "def is_outside_X_std(numbers, number_to_check, X):\n",
    "    mean = sum(numbers) / len(numbers)\n",
    "    std_dev = (sum((x - mean) ** 2 for x in numbers) / len(numbers)) ** 0.5\n",
    "    lower_bound = mean - X * std_dev\n",
    "    upper_bound = mean + X * std_dev\n",
    "    return number_to_check < lower_bound or number_to_check > upper_bound\n",
    "\n",
    "for subj in final_data.subjID.unique():\n",
    "    subj_df = final_data.loc[final_data['subjID']==subj]\n",
    "    subj_std = subj_df['depth_estimate'].std()\n",
    "    if is_outside_X_std(all_stds, subj_std, 3):\n",
    "        values_to_drop.append(subj)\n",
    "        print(subj)\n",
    "    else:\n",
    "        pass\n",
    "        # print(f\"The subject {subj} is inside the range of mean ± 3 standard deviations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Remove rows where the 'ID' column is in the list of values_to_drop\n",
    "df_filtered = final_data[~final_data['subjID'].isin(values_to_drop)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-Score Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscored_outcomes(df):\n",
    "    '''\n",
    "    z-score depth estimates and RTs:\n",
    "        for each subj calculate their avg and std \n",
    "        zscored = (estim - subj avg)/subj std\n",
    "    '''\n",
    "    #List unique values in the df['subjID'] column\n",
    "    all_subjIDs = df.subjID.unique()\n",
    "    \n",
    "    df2_list = []\n",
    "    for subj in all_subjIDs:\n",
    "        subj_df = df.loc[df['subjID'] == subj]\n",
    "        final_subj_df = subj_df.copy(deep=True) # prevent setting with copy warning \n",
    "        \n",
    "        # Z-Score depth estimates\n",
    "        average_estim = subj_df[\"depth_estimate\"].mean()\n",
    "        std_estim = subj_df[\"depth_estimate\"].std()\n",
    "        subj_depth_estimates = np.array(list(subj_df[\"depth_estimate\"]))\n",
    "        zscored_subj_depth_estimates = (subj_depth_estimates - average_estim)/std_estim\n",
    "\n",
    "        final_subj_df['zs_depth_estimates'] = zscored_subj_depth_estimates\n",
    "\n",
    "        # Z-Score actual depth\n",
    "        average_AD = subj_df[\"actual_depth\"].mean()\n",
    "        std_AD = subj_df[\"actual_depth\"].std()\n",
    "        subj_AD = np.array(list(subj_df[\"actual_depth\"]))\n",
    "        zscored_subj_AD = (subj_AD - average_AD)/std_AD\n",
    "\n",
    "        final_subj_df['zs_actual_depth'] = zscored_subj_AD\n",
    "\n",
    "        # Z-Score RT\n",
    "        average_RT = subj_df[\"trial_RT\"].mean()\n",
    "        std_RT = subj_df[\"trial_RT\"].std()\n",
    "        subj_RTs = np.array(list(subj_df[\"trial_RT\"]))\n",
    "        zscored_subj_RTs = (subj_RTs - average_RT)/std_RT\n",
    "\n",
    "        final_subj_df['zs_trial_RT'] = zscored_subj_RTs\n",
    "        df2_list.append(final_subj_df)\n",
    "    \n",
    "    df2 = pd.concat(df2_list)    \n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscored_final_data = zscored_outcomes(final_data)\n",
    "\n",
    "filtered_zscored_final_data = zscored_outcomes(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'condition' based on the content of 'stimulus'\n",
    "zscored_final_data['condition'] = zscored_final_data['stimulus'].apply(lambda x: 'BC' if 'BC' in x else 'FS')\n",
    "\n",
    "# Create a new column 'condition' based on the content of 'stimulus'\n",
    "filtered_zscored_final_data['condition'] = filtered_zscored_final_data['stimulus'].apply(lambda x: 'BC' if 'BC' in x else 'FS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest = '/Users/prachimahableshwarkar/Documents/GW/Depth_MTurk/familiarSize/data/'\n",
    "label = 'tx-MX-data-1000ms.csv'\n",
    "\n",
    "zscored_final_data.to_csv(dest + label , index=True)\n",
    "\n",
    "filtered_zscored_final_data.to_csv(dest + 'filtered-'+label, index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
